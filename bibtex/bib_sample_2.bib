
@article{lommatzsch_information_nodate,
	title = {An {Information} {Retrieval}-based {Approach} for {Building} {Intuitive} {Chatbots} for {Large} {Knowledge} {Bases}},
	abstract = {Finding quickly the relevant information is essential in many application scenarios. In the past years, huge data collections have been created, but for most users it is still very diﬃcult to ﬁnd the information relevant for a speciﬁc, often complex problem. With the advances in automatic language processing chatbots have been developed to simplify the information search providing an intuitive user interface that gives the user the needed information in a natural dialog.},
	language = {en},
	author = {Lommatzsch, Andreas and Katins, Jonas},
	pages = {10},
	file = {Lommatzsch and Katins - An Information Retrieval-based Approach for Buildi.pdf:/Users/marwah/Zotero/storage/9EXLYEM5/Lommatzsch and Katins - An Information Retrieval-based Approach for Buildi.pdf:application/pdf},
}

@inproceedings{lim_estimating_2016,
	address = {Caulfield VIC Australia},
	title = {Estimating {Domain}-{Specific} {User} {Expertise} for {Answer} {Retrieval} in {Community} {Question}-{Answering} {Platforms}},
	isbn = {978-1-4503-4865-2},
	url = {https://dl.acm.org/doi/10.1145/3015022.3015032},
	doi = {10.1145/3015022.3015032},
	abstract = {Community Question-Answering (CQA) platforms leverage the inherent wisdom of the crowd – enabling users to retrieve quality information from domain experts through natural language. An important and challenging task is to identify reliable and trusted experts on large popular CQA platforms. State-of-the-art graph-based approaches to expertise estimation consider only user-user interactions without taking the relative contribution of individual answers into account, while pairwise-comparison approaches consider only pairs involving the best-answerer of each question. This research argues that there is a need to account for the user’s relative contribution towards solving the question when estimating user expertise and proposes a content-agnostic measure of user contributions. This addition is incorporated into a competition-based approach for ranking users’ question answering ability. The paper analyses how improvements in user expertise estimation impact on applications in expert search and answer quality prediction. Experiments using the Yahoo! Chiebukuro data show encouraging performance improvements and robustness over state-of-the-art approaches.},
	language = {en},
	urldate = {2022-02-19},
	booktitle = {Proceedings of the 21st {Australasian} {Document} {Computing} {Symposium}},
	publisher = {ACM},
	author = {Lim, Wern Han and Carman, Mark James and Wong, Sze-Meng Jojo},
	month = dec,
	year = {2016},
	pages = {33--40},
	file = {Lim et al. - 2016 - Estimating Domain-Specific User Expertise for Answ.pdf:/Users/marwah/Zotero/storage/GIRCEWQ9/Lim et al. - 2016 - Estimating Domain-Specific User Expertise for Answ.pdf:application/pdf},
}

@article{breja_why-type_2022,
	title = {Why-{Type} {Question} to {Query} {Reformulation} for {Efficient} {Document} {Retrieval}:},
	volume = {12},
	issn = {2155-6377, 2155-6385},
	shorttitle = {Why-{Type} {Question} to {Query} {Reformulation} for {Efficient} {Document} {Retrieval}},
	url = {https://services.igi-global.com/resolvedoi/resolve.aspx?doi=10.4018/IJIRR.289948},
	doi = {10.4018/IJIRR.289948},
	abstract = {Understanding the actual need of users from a question is very crucial in non-factoid why-question answering as why-questions are complex and involve ambiguity and redundancy in their understanding. The precise requirement is to determine the focus of question and reformulate them accordingly to retrieve expected answers to a question. The paper analyzes different types of why-questions and proposes an algorithm for each class to determine the focus and reformulate it into a query by appending focal terms and cue phrase ‘because’ with it. Further, a user interface is implemented which asks input why-question, applies different components of question, reformulates it, and finally, retrieves web pages by posing query to Google search engine. To measure the accuracy of the process, user feedback is taken which asks them to assign scoring from 1 to 10, on how relevant are the retrieved web pages according to their understanding. The results depict that maximum precision of 89\% is achieved in informational type why-questions and minimum of 48\% in opinionated type why-questions.},
	language = {en},
	number = {1},
	urldate = {2022-02-19},
	journal = {International Journal of Information Retrieval Research},
	author = {Breja, Manvi and Jain, Sanjay Kumar},
	month = jan,
	year = {2022},
	pages = {1--18},
	file = {Breja and Jain - 2022 - Why-Type Question to Query Reformulation for Effic:/Users/marwah/Zotero/storage/Q5I6WI7Q/Breja and Jain - 2022 - Why-Type Question to Query Reformulation for Effic:application/pdf},
}

@inproceedings{chatterjee_why_2019,
	address = {Santa Clara CA USA},
	title = {Why does this {Entity} matter?: {Support} {Passage} {Retrieval} for {Entity} {Retrieval}},
	isbn = {978-1-4503-6881-0},
	shorttitle = {Why does this {Entity} matter?},
	url = {https://dl.acm.org/doi/10.1145/3341981.3344243},
	doi = {10.1145/3341981.3344243},
	abstract = {Our goal is to complement an entity ranking with human-readable explanations of how those retrieved entities are connected to the information need. While related to the problem of support passage retrieval, in this paper, we explore two underutilized indicators of relevance: contextual entities and entity salience. The effectiveness of the indicators are studied within a supervised learning-to-rank framework on a dataset from TREC Complex Answer Retrieval. We find that salience is a useful indicator, but it is often not applicable. In contrast, although performance improvements are obtained by using contextual entities, using contextual words still outperforms contextual entities.},
	language = {en},
	urldate = {2022-02-19},
	booktitle = {Proceedings of the 2019 {ACM} {SIGIR} {International} {Conference} on {Theory} of {Information} {Retrieval}},
	publisher = {ACM},
	author = {Chatterjee, Shubham and Dietz, Laura},
	month = sep,
	year = {2019},
	pages = {221--224},
	file = {Chatterjee and Dietz - 2019 - Why does this Entity matter Support Passage Retr.pdf:/Users/marwah/Zotero/storage/GKQVESHP/Chatterjee and Dietz - 2019 - Why does this Entity matter Support Passage Retr.pdf:application/pdf},
}

@article{quarteroni_user_nodate,
	title = {User {Modelling} for {Adaptive} {Question} {Answering} and {Information} {Retrieval}},
	abstract = {Most question answering (QA) and information retrieval (IR) systems are insensitive to different users’ needs and preferences, and also to the existence of multiple, complex or controversial answers. We propose the notion of adaptivity in QA and IR by introducing a hybrid QA-IR system based on a user model. Our current prototype ﬁlters and re-ranks the query results returned by a search engine according to their reading level. This is particularly useful in school environments, where it is most needed to adjust the presentation of complex information to the pupils’ level of understanding. Keywords: adaptive systems, question answering, information retrieval, user modelling, readability.},
	language = {en},
	author = {Quarteroni, Silvia and Manandhar, Suresh},
	pages = {6},
	file = {Quarteroni and Manandhar - User Modelling for Adaptive Question Answering and.pdf:/Users/marwah/Zotero/storage/FFAMY3DH/Quarteroni and Manandhar - User Modelling for Adaptive Question Answering and.pdf:application/pdf},
}

@inproceedings{aliannejadi_harnessing_2020,
	address = {Vancouver BC Canada},
	title = {Harnessing {Evolution} of {Multi}-{Turn} {Conversations} for {Effective} {Answer} {Retrieval}},
	isbn = {978-1-4503-6892-6},
	url = {https://dl.acm.org/doi/10.1145/3343413.3377968},
	doi = {10.1145/3343413.3377968},
	abstract = {With the improvements in speech recognition and voice generation technologies over the last years, a lot of companies have sought to develop conversation understanding systems that run on mobile phones or smart home devices through natural language interfaces. Conversational assistants, such as Google Assistant™ and Microsoft Cortana™, can help users to complete various types of tasks. This requires an accurate understanding of the user’s information need as the conversation evolves into multiple turns. Finding relevant context in a conversation’s history is challenging because of the complexity of natural language and the evolution of a user’s information need. In this work, we present an extensive analysis of language, relevance, dependency of user utterances in a multi-turn information-seeking conversation. To this aim, we have annotated relevant utterances in the conversations released by the TREC CaST 2019 track. The annotation labels determine which of the previous utterances in a conversation can be used to improve the current one. Furthermore, we propose a neural utterance relevance model based on BERT fine-tuning, outperforming competitive baselines. We study and compare the performance of multiple retrieval models, utilizing different strategies to incorporate the user’s context. The experimental results on both classification and retrieval tasks show that our proposed approach can effectively identify and incorporate the conversation context. We show that processing the current utterance using the predicted relevant utterance leads to a 38\% relative improvement in terms of nDCG@20. Finally, to foster research in this area, we have released the dataset of the annotations.},
	language = {en},
	urldate = {2022-02-19},
	booktitle = {Proceedings of the 2020 {Conference} on {Human} {Information} {Interaction} and {Retrieval}},
	publisher = {ACM},
	author = {Aliannejadi, Mohammad and Chakraborty, Manajit and Ríssola, Esteban Andrés and Crestani, Fabio},
	month = mar,
	year = {2020},
	pages = {33--42},
	file = {Aliannejadi et al. - 2020 - Harnessing Evolution of Multi-Turn Conversations f.pdf:/Users/marwah/Zotero/storage/ILW9E857/Aliannejadi et al. - 2020 - Harnessing Evolution of Multi-Turn Conversations f.pdf:application/pdf},
}

@article{yu_crossing_2020,
	title = {Crossing {Variational} {Autoencoders} for {Answer} {Retrieval}},
	url = {http://arxiv.org/abs/2005.02557},
	abstract = {Answer retrieval is to ﬁnd the most aligned answer from a large set of candidates given a question. Learning vector representations of questions/answers is the key factor. Questionanswer alignment and question/answer semantics are two important signals for learning the representations. Existing methods learned semantic representations with dual encoders or dual variational auto-encoders. The semantic information was learned from language models or question-to-question (answer-to-answer) generative processes. However, the alignment and semantics were too separate to capture the aligned semantics between question and answer. In this work, we propose to cross variational auto-encoders by generating questions with aligned answers and generating answers with aligned questions. Experiments show that our method outperforms the state-of-theart answer retrieval method on SQuAD.},
	language = {en},
	urldate = {2022-02-19},
	journal = {arXiv:2005.02557 [cs]},
	author = {Yu, Wenhao and Wu, Lingfei and Zeng, Qingkai and Tao, Shu and Deng, Yu and Jiang, Meng},
	month = jul,
	year = {2020},
	note = {arXiv: 2005.02557},
	keywords = {Computer Science - Computation and Language, Computer Science - Information Retrieval},
	file = {Yu et al. - 2020 - Crossing Variational Autoencoders for Answer Retri.pdf:/Users/marwah/Zotero/storage/LG9EBN2Y/Yu et al. - 2020 - Crossing Variational Autoencoders for Answer Retri.pdf:application/pdf},
}

@article{dietz_trec_nodate,
	title = {{TREC} {Complex} {Answer} {Retrieval} {Overview}},
	abstract = {This notebook gives an overview of activities, datasets, and results of the second year of TREC Complex Answer Retrieval. We lay out the tasks o ered and how provided datasets are automatically derived from Wikipedia and TQA. Manual relevance assessments are created by NIST. We describe the details of the assessment procedures, inter-annotator agreement, and statistics. Nine teams submitted runs exploring interactions of entities and passages, neural as well as traditional retrieval methods. We see that combining traditional methods with learning-to-rank can outperform neural methods, even when many training queries are available.},
	language = {en},
	author = {Dietz, Laura and Gamari, Ben and Craswell, Nick},
	pages = {17},
	file = {Dietz et al. - TREC Complex Answer Retrieval Overview.pdf:/Users/marwah/Zotero/storage/LRGGSZLB/Dietz et al. - TREC Complex Answer Retrieval Overview.pdf:application/pdf},
}

@article{wei_table_2006,
	title = {Table extraction for answer retrieval},
	volume = {9},
	issn = {1386-4564, 1573-7659},
	url = {http://link.springer.com/10.1007/s10791-006-9005-5},
	doi = {10.1007/s10791-006-9005-5},
	abstract = {The ability to ﬁnd tables and extract information from them is a necessary component of many information retrieval tasks. Documents often contain tables in order to communicate densely packed, multi-dimensional information. Tables do this by employing layout patterns to efﬁciently indicate ﬁelds and records in two-dimensional form. Their rich combination of formatting and content presents difﬁculties for traditional retrieval techniques. This paper describes techniques for extracting tables from text and retrieving answers from the extracted information. We compare machine learning (especially, Conditional Random Fields) and heuristic methods for table extraction. To retrieve answers, our approach creates a cell document, which contains the cell and its metadata (headers, titles) for each table cell, and the retrieval model ranks the cells of the extracted tables using a language-modeling approach. Performance is tested using government statistical Web sites and news articles, and errors are analyzed in order to improve the system.},
	language = {en},
	number = {5},
	urldate = {2022-02-19},
	journal = {Information Retrieval},
	author = {Wei, Xing and Croft, Bruce and McCallum, Andrew},
	month = nov,
	year = {2006},
	pages = {589--611},
	file = {Wei et al. - 2006 - Table extraction for answer retrieval.pdf:/Users/marwah/Zotero/storage/2URQSURA/Wei et al. - 2006 - Table extraction for answer retrieval.pdf:application/pdf},
}

@article{croft_importance_2019,
	title = {The {Importance} of {Interaction} in {Information} {Retrieval}},
	language = {en},
	author = {Croft, Bruce},
	year = {2019},
	pages = {64},
	file = {Croft - 2019 - The Importance of Interaction in Information Retri.pdf:/Users/marwah/Zotero/storage/VJNUJMJA/Croft - 2019 - The Importance of Interaction in Information Retri.pdf:application/pdf},
}

@article{mass_study_2019,
	title = {A {Study} of {BERT} for {Non}-{Factoid} {Question}-{Answering} under {Passage} {Length} {Constraints}},
	url = {http://arxiv.org/abs/1908.06780},
	abstract = {We study the use of BERT for non-factoid question-answering, focusing on the passage re-ranking task under varying passage lengths. To this end, we explore the ﬁnetuning of BERT in different learning-to-rank setups, comprising both point-wise and pairwise methods, resulting in substantial improvements over the state-of-the-art. We then analyze the effectiveness of BERT for different passage lengths and suggest how to cope with large passages.},
	language = {en},
	urldate = {2022-02-19},
	journal = {arXiv:1908.06780 [cs]},
	author = {Mass, Yosi and Roitman, Haggai and Erera, Shai and Rivlin, Or and Weiner, Bar and Konopnicki, David},
	month = aug,
	year = {2019},
	note = {arXiv: 1908.06780},
	keywords = {Computer Science - Computation and Language, Computer Science - Information Retrieval},
	file = {Mass et al. - 2019 - A Study of BERT for Non-Factoid Question-Answering.pdf:/Users/marwah/Zotero/storage/6NVWK68V/Mass et al. - 2019 - A Study of BERT for Non-Factoid Question-Answering.pdf:application/pdf},
}

@phdthesis{bi_neural_nodate,
	title = {Neural {Approaches} to {Feedback} in {Information} {Retrieval}},
	url = {https://scholarworks.umass.edu/dissertations_2/2275},
	abstract = {Relevance feedback on search results indicates users' search intent and preferences. Extensive studies have shown that incorporating relevance feedback (RF) on the top k (usually 10) ranked results significantly improves the performance of re-ranking. However, most existing research on user feedback focuses on words-based retrieval models. Recently, neural retrieval models have shown their efficacy in capturing relevance matching in retrieval but little research has been conducted on neural approaches to feedback. This leads us to study different aspects of feedback with neural approaches in the dissertation.
RF techniques are seldom used in real search scenarios since they can require significant manual efforts to obtain explicit judgments for search results. However, with mobile or voice-based intelligent assistants being more popular nowadays, user feedback of result quality could be collected potentially during their interactions with the assistants. We study both positive and negative RF to refine the re-ranking performance. Positive feedback aims to find more relevant results given some known relevant results while negative feedback targets identifying the first relevant result. In most cases, it is more beneficial to find the first relevant result compared with finding additional relevant results. However, negative feedback is much more challenging than positive feedback since relevant results are usually similar while non-relevant results could vary considerably.
We focus on the tasks of text retrieval and product search to study the different aspects of incorporating feedback for ranking refinement with neural approaches. Our contributions are: (1) we show that iterative relevance feedback (IRF) is more effective than top-k RF on answer passages and we further improve IRF with neural approaches; (2) we propose an effective RF technique based on neural models for product search; (3) we study how to refine re-ranking with negative feedback for conversational product search; (4) we leverage negative feedback in user responses to ask clarifying questions in open-domain conversational search. Our research improves retrieval performance by incorporating feedback in interactive retrieval and approaches multi-turn conversational information-seeking tasks with a focus on positive and negative feedback.},
	language = {en},
	urldate = {2022-02-19},
	school = {University of Massachusetts Amherst},
	author = {Bi, Keping},
	doi = {10.7275/23988667},
	file = {Bi - Neural Approaches to Feedback in Information Retri.pdf:/Users/marwah/Zotero/storage/BQMCBMUN/Bi - Neural Approaches to Feedback in Information Retri.pdf:application/pdf},
}

@inproceedings{yulianti_using_2016,
	address = {Caulfield VIC Australia},
	title = {Using {Semantic} and {Context} {Features} for {Answer} {Summary} {Extraction}},
	isbn = {978-1-4503-4865-2},
	url = {https://dl.acm.org/doi/10.1145/3015022.3015031},
	doi = {10.1145/3015022.3015031},
	abstract = {The summary length is set to the nearest integer length of the ground truth answers (i.e. 2.67: three sentences). A combination of query-biased [8], semantic, and context features [13] were used to identify sentences that contain answers from each document.},
	language = {en},
	urldate = {2022-02-19},
	booktitle = {Proceedings of the 21st {Australasian} {Document} {Computing} {Symposium}},
	publisher = {ACM},
	author = {Yulianti, Evi and Chen, Ruey-Cheng and Scholer, Falk and Sanderson, Mark},
	month = dec,
	year = {2016},
	pages = {81--84},
	file = {1963405.1963413.pdf:/Users/marwah/Zotero/storage/RIEUPXVN/1963405.1963413.pdf:application/pdf;Yulianti et al. - 2016 - Using Semantic and Context Features for Answer Sum.pdf:/Users/marwah/Zotero/storage/CQ4HJ9BK/Yulianti et al. - 2016 - Using Semantic and Context Features for Answer Sum.pdf:application/pdf},
}

@article{kulkarni_thesis_nodate,
	title = {A {THESIS} {SUBMITTED} {TO} {THE} {FACULTY} {OF} {THE} {GRADUATE} {SCHOOL} {OF} {THE} {UNIVERSITY} {OF} {MINNESOTA}},
	language = {en},
	author = {Kulkarni, Sameer},
	pages = {63},
	file = {A_Sentiment_Based_Non-Factoid_Question-Answering_Framework.pdf:/Users/marwah/Zotero/storage/UWI3UH78/A_Sentiment_Based_Non-Factoid_Question-Answering_Framework.pdf:application/pdf;Kulkarni - A THESIS SUBMITTED TO THE FACULTY OF THE GRADUATE .pdf:/Users/marwah/Zotero/storage/FECE53ER/Kulkarni - A THESIS SUBMITTED TO THE FACULTY OF THE GRADUATE .pdf:application/pdf},
}


@inproceedings{xu_preferred_2018,
	address = {Brussels, Belgium},
	title = {Preferred {Answer} {Selection} in {Stack} {Overflow}: {Better} {Text} {Representations} ... and {Metadata}, {Metadata}, {Metadata}},
	shorttitle = {Preferred {Answer} {Selection} in {Stack} {Overflow}},
	url = {http://aclweb.org/anthology/W18-6119},
	doi = {10.18653/v1/W18-6119},
	abstract = {Community question answering (cQA) forums provide a rich source of data for facilitating non-factoid question answering over many technical domains. Given this, there is considerable interest in answer retrieval from these kinds of forums. However this is a difﬁcult task as the structure of these forums is very rich, and both metadata and text features are important for successful retrieval. While there has recently been a lot of work on solving this problem using deep learning models applied to question/answer text, this work has not looked at how to make use of the rich metadata available in cQA forums. We propose an attentionbased model which achieves state-of-the-art results for text-based answer selection alone, and by making use of complementary metadata, achieves a substantially higher result over two reference datasets novel to this work.},
	language = {en},
	urldate = {2022-02-19},
	booktitle = {Proceedings of the 2018 {EMNLP} {Workshop} {W}-{NUT}: {The} 4th {Workshop} on {Noisy} {User}-generated {Text}},
	publisher = {Association for Computational Linguistics},
	author = {Xu, Steven and Bennett, Andrew and Hoogeveen, Doris and Lau, Jey Han and Baldwin, Timothy},
	year = {2018},
	pages = {137--147},
	file = {Xu et al. - 2018 - Preferred Answer Selection in Stack Overflow Bett.pdf:/Users/marwah/Zotero/storage/LTBF2J3A/Xu et al. - 2018 - Preferred Answer Selection in Stack Overflow Bett.pdf:application/pdf},
}

@article{dulceanu_photoshopquia_nodate,
	title = {{PhotoshopQuiA}: {A} {Corpus} of {Non}-{Factoid} {Questions} and {Answers} for {Why}-{Question} {Answering}},
	abstract = {Recent years have witnessed a high interest in non-factoid question answering using Community Question Answering (CQA) web sites. Despite ongoing research using state-of-the-art methods, there is a scarcity of available datasets for this task. Why-questions, which play an important role in open-domain and domain-speciﬁc applications, are difﬁcult to answer automatically since the answers need to be constructed based on different information extracted from multiple knowledge sources. We introduce the PhotoshopQuiA dataset, a new publicly available set of 2,854 why-question and answer(s) (WhyQ, A) pairs related to Adobe Photoshop usage collected from ﬁve CQA web sites. We chose Adobe Photoshop because it is a popular and well-known product, with a lively, knowledgeable and sizable community. To the best of our knowledge, this is the ﬁrst English dataset for Why-QA that focuses on a product, as opposed to previous open-domain datasets. The corpus is stored in JSON format and contains detailed data about questions and questioners as well as answers and answerers. The dataset can be used to build Why-QA systems, to evaluate current approaches for answering why-questions, and to develop new models for future QA systems research.},
	language = {en},
	author = {Dulceanu, Andrei and Dinh, Thang Le and Chang, Walter and Bui, Trung and Kim, Doo Soon and Vu, Manh Chien and Kim, Seokhwan},
	pages = {8},
	file = {Dulceanu et al. - PhotoshopQuiA A Corpus of Non-Factoid Questions a.pdf:/Users/marwah/Zotero/storage/8HIEJESC/Dulceanu et al. - PhotoshopQuiA A Corpus of Non-Factoid Questions a.pdf:application/pdf},
}

@inproceedings{chen_harnessing_2015,
	address = {Melbourne Australia},
	title = {Harnessing {Semantics} for {Answer} {Sentence} {Retrieval}},
	isbn = {978-1-4503-3790-8},
	url = {https://dl.acm.org/doi/10.1145/2810133.2810136},
	doi = {10.1145/2810133.2810136},
	abstract = {Finding answer passages from the Web is a challenging task. One major diﬃculty is to retrieve sentences that may not have many terms in common with the question. In this paper, we experiment with two semantic approaches for ﬁnding non-factoid answers using a learning-to-rank retrieval setting. We show that using semantic representations learned from external resources such as Wikipedia or Google News may substantially improve the quality of top-ranked retrieved answers.},
	language = {en},
	urldate = {2022-02-19},
	booktitle = {Proceedings of the {Eighth} {Workshop} on {Exploiting} {Semantic} {Annotations} in {Information} {Retrieval}},
	publisher = {ACM},
	author = {Chen, Ruey-Cheng and Spina, Damiano and Croft, W. Bruce and Sanderson, Mark and Scholer, Falk},
	month = oct,
	year = {2015},
	pages = {21--27},
	file = {Chen et al. - 2015 - Harnessing Semantics for Answer Sentence Retrieval.pdf:/Users/marwah/Zotero/storage/L3BY6C6A/Chen et al. - 2015 - Harnessing Semantics for Answer Sentence Retrieval.pdf:application/pdf},
}

@article{savolainen_sense-making_1993,
	title = {The sense-making theory: {Reviewing} the interests of a user-centered approach to information seeking and use},
	volume = {29},
	issn = {03064573},
	shorttitle = {The sense-making theory},
	url = {https://linkinghub.elsevier.com/retrieve/pii/030645739390020E},
	doi = {10.1016/0306-4573(93)90020-E},
	abstract = {The sense-making theory of Brenda Dervin, based on constructivist assumptions on human information seeking and use, is reviewed. The study focuses on the epistemic and practical interests of the theory, discussing them in relation to the interests of the traditional intermediary-centered approach. The interests of the theory are reviewed by analyzing its conceptions of information, information seeking and use, structure, and action. In addition, the assumptions of the theory are assessed in the context of the recent developments of social science and methodology. Finally, the paradigmatic demands of the theory for the study of information seeking and use are considered. Sense-making theory, having its strongest roots in communication research, is a programmatic research effort suggesting user-centered ideas for the conceptualization of information seeking and use. The theoretical assumptions of the theory based on the metaphors of situation-gap-uses/helps has been validated in numerous empirical studies. As to LIS research at large, the major contribution of the present theory seems to be the inspiring critique addressed to the limitations of the traditional intermediary-centered approach.},
	language = {en},
	number = {1},
	urldate = {2022-02-19},
	journal = {Information Processing \& Management},
	author = {Savolainen, Reijo},
	month = jan,
	year = {1993},
	pages = {13--28},
	file = {Savolainen - 1993 - The sense-making theory Reviewing the interests o.pdf:/Users/marwah/Zotero/storage/3GYCPIFI/Savolainen - 1993 - The sense-making theory Reviewing the interests o.pdf:application/pdf},
}

@article{zamani_conversational_2022,
	title = {Conversational {Information} {Seeking}},
	url = {http://arxiv.org/abs/2201.08808},
	abstract = {Conversational information seeking (CIS) is concerned with a sequence of interactions between one or more users and an information system. Interactions in CIS are primarily based on natural language dialogue, while they may include other types of interactions, such as click, touch, and body gestures. This monograph provides a thorough overview of CIS definitions, applications, interactions, interfaces, design, implementation, and evaluation. This monograph views CIS applications as including conversational search, conversational question answering, and conversational recommendation. Our aim is to provide an overview of past research related to CIS, introduce the current state-of-the-art in CIS, highlight the challenges still being faced in the community. and suggest future directions.},
	language = {en},
	urldate = {2022-02-20},
	journal = {arXiv:2201.08808 [cs]},
	author = {Zamani, Hamed and Trippas, Johanne R. and Dalton, Jeff and Radlinski, Filip},
	month = jan,
	year = {2022},
	note = {arXiv: 2201.08808},
	keywords = {Computer Science - Computation and Language, Computer Science - Human-Computer Interaction, Computer Science - Information Retrieval},
	file = {Zamani et al. - 2022 - Conversational Information Seeking.pdf:/Users/marwah/Zotero/storage/Y5JJ5ETL/Zamani et al. - 2022 - Conversational Information Seeking.pdf:application/pdf},
}

@article{dalton_trec_2020,
	title = {{TREC} {CAsT} 2019: {The} {Conversational} {Assistance} {Track} {Overview}},
	shorttitle = {{TREC} {CAsT} 2019},
	url = {http://arxiv.org/abs/2003.13624},
	abstract = {The Conversational Assistance Track (CAsT) is a new track for TREC 2019 to facilitate Conversational Information Seeking (CIS) research and to create a large-scale reusable test collection for conversational search systems. The document corpus is 38,426,252 passages from the TREC Complex Answer Retrieval (CAR) and Microsoft MAchine Reading COmprehension (MARCO) datasets. Eighty information seeking dialogues (30 train, 50 test) are an average of 9 to 10 questions long. Relevance assessments are provided for 30 training topics and 20 test topics. This year 21 groups submitted a total of 65 runs using varying methods for conversational query understanding and ranking. Methods include traditional retrieval based methods, feature based learning-to-rank, neural models, and knowledge enhanced methods. A common theme through the runs is the use of BERT-based neural reranking methods. Leading methods also employed document expansion, conversational query expansion, and generative language models for conversational query rewriting (GPT-2). The results show a gap between automatic systems and those using the manually resolved utterances, with a 35\% relative improvement of manual rewrites over the best automatic system.},
	language = {en},
	urldate = {2022-03-04},
	journal = {arXiv:2003.13624 [cs]},
	author = {Dalton, Jeffrey and Xiong, Chenyan and Callan, Jamie},
	month = mar,
	year = {2020},
	note = {arXiv: 2003.13624},
	keywords = {Computer Science - Computation and Language, Computer Science - Information Retrieval, Computer Science - Machine Learning},
	file = {Dalton et al. - 2020 - TREC CAsT 2019 The Conversational Assistance Trac.pdf:/Users/marwah/Zotero/storage/S62KGVRD/Dalton et al. - 2020 - TREC CAsT 2019 The Conversational Assistance Trac.pdf:application/pdf},
}

@article{lee_formation_nodate,
	title = {Formation of {Information} {Need} as a {Questioning}: {A} {Conceptual} {Representation} for {Semantic} {Web} based {QA} {System}},
	abstract = {Questioning is a formation of information need where an asker is aware of an anomalous state of knowledge. Such awareness can only emerge when a user encounters to certain contextual circumstance. Either user's surroundings in reality (location, back-ground music, etc.) or web (news article, blog, video, social network, etc.) can be a certain contextual circumstance. By examining a simple question "What triggers question?", we concluded that a certain contextual circumstance drives a question where an asker is aware of anomalous state of knowledge. We also identified a direct and indirect channels expressing contrastive types unfolding from a potential asker's contextual situation input to a formation of information need. Such channels could potentially serve as a medium of personalized model for predicting, adjusting, and retrieving user's need of information. Further application of "ambient" feature that readily captures a certain contextual circumstance, subjectively questions to QA system based on user's pattern and answer retrieval without a user’s (potential asker's) query will envisage a step closer to AI-complete QA system.},
	language = {en},
	author = {Lee, Yongju and Yang, Sungkwon and Jang, Sueun and Kim, Hong-Gee},
	pages = {7},
	file = {Lee et al. - Formation of Information Need as a Questioning A .pdf:/Users/marwah/Zotero/storage/PK8FU4HT/Lee et al. - Formation of Information Need as a Questioning A .pdf:application/pdf},
}

@inproceedings{qu_analyzing_2018,
	address = {Ann Arbor MI USA},
	title = {Analyzing and {Characterizing} {User} {Intent} in {Information}-seeking {Conversations}},
	isbn = {978-1-4503-5657-2},
	url = {https://dl.acm.org/doi/10.1145/3209978.3210124},
	doi = {10.1145/3209978.3210124},
	abstract = {Understanding and characterizing how people interact in informationseeking conversations is crucial in developing conversational search systems. In this paper, we introduce a new dataset designed for this purpose and use it to analyze information-seeking conversations by user intent distribution, co-occurrence, and flow patterns. The MSDialog dataset is a labeled dialog dataset of question answering (QA) interactions between information seekers and providers from an online forum on Microsoft products. The dataset contains more than 2,000 multi-turn QA dialogs with 10,000 utterances that are annotated with user intent on the utterance level. Annotations were done using crowdsourcing. With MSDialog, we find some highly recurring patterns in user intent during an information-seeking process. They could be useful for designing conversational search systems. We will make our dataset freely available to encourage exploration of information-seeking conversation models.},
	language = {en},
	urldate = {2022-03-04},
	booktitle = {The 41st {International} {ACM} {SIGIR} {Conference} on {Research} \& {Development} in {Information} {Retrieval}},
	publisher = {ACM},
	author = {Qu, Chen and Yang, Liu and Croft, W. Bruce and Trippas, Johanne R. and Zhang, Yongfeng and Qiu, Minghui},
	month = jun,
	year = {2018},
	pages = {989--992},
	file = {Qu et al. - 2018 - Analyzing and Characterizing User Intent in Inform.pdf:/Users/marwah/Zotero/storage/7X48EGQH/Qu et al. - 2018 - Analyzing and Characterizing User Intent in Inform.pdf:application/pdf},
}

@phdthesis{qu_history_nodate,
	title = {History {Modeling} for {Conversational} {Information} {Retrieval}},
	url = {https://scholarworks.umass.edu/dissertations_2/2306},
	abstract = {Conversational search is an embodiment of an iterative and interactive approach to information retrieval (IR) that has been studied for decades. Due to the recent rise of intelligent personal assistants, such as Siri, Alexa, AliMe, Cortana, and Google Assistant, a growing part of the population is moving their information-seeking activities to voice- or text-based conversational interfaces. One of the major challenges of conversational search is to leverage the conversation history to understand and fulfill the users' information needs. In this dissertation work, we investigate history modeling approaches for conversational information retrieval. We start from history modeling for user intent prediction. We analyze information-seeking conversations by user intent distribution, co-occurrence, and flow patterns, followed by a study of user intent prediction in an information-seeking setting with both feature-based methods and deep learning methods. We then move to history modeling for conversational question answering (ConvQA), which can be considered as a simplified setting of conversational search. We first propose a positional history answer embedding (PosHAE) method to seamlessly integrate conversation history into a ConvQA model based on BERT. We then build upon this method and design a history attention mechanism (HAM) to conduct a ``soft selection'' for conversation history. After this, we extend the previous ConvQA task to an open-retrieval (ORConvQA) setting to emphasize the fundamental role of retrieval in conversational search. In this setting, we learn to retrieve evidence from a large collection before extracting answers. We build an end-to-end system for ORConvQA, featuring a learnable dense retriever. We conduct experiments with both fully-supervised and weakly-supervised approaches to tackle the training challenges of ORConvQA. Finally, we study history modeling for conversational re-ranking. Given a history of user feedback behaviors, such as issuing a query, clicking a document, and skipping a document, we propose to introduce behavior awareness to a neural ranker. Our experimental results show that the history modeling approaches proposed in this dissertation can effectively improve the performance of different conversation tasks and provide new insights into conversational information retrieval.},
	language = {en},
	urldate = {2022-03-04},
	school = {University of Massachusetts Amherst},
	author = {Qu, Chen},
	doi = {10.7275/22880834},
	file = {Qu - History Modeling for Conversational Information Re.pdf:/Users/marwah/Zotero/storage/2PHIMRNI/Qu - History Modeling for Conversational Information Re.pdf:application/pdf},
}

@article{djeddal_does_2021,
	title = {Does {Structure} {Matter}? {Leveraging} {Data}-to-{Text} {Generation} for {Answering} {Complex} {Information} {Needs}},
	shorttitle = {Does {Structure} {Matter}?},
	url = {http://arxiv.org/abs/2112.04344},
	abstract = {In this work, our aim is to provide a structured answer in natural language to a complex information need. Particularly, we envision using generative models from the perspective of data-to-text generation. We propose the use of a content selection and planning pipeline which aims at structuring the answer by generating intermediate plans. The experimental evaluation is performed using the TREC Complex Answer Retrieval (CAR) dataset. We evaluate both the generated answer and its corresponding structure and show the eﬀectiveness of planning-based models in comparison to a text-to-text model.},
	language = {en},
	urldate = {2022-03-04},
	journal = {arXiv:2112.04344 [cs]},
	author = {Djeddal, Hanane and Gerald, Thomas and Soulier, Laure and Pinel-Sauvagnat, Karen and Tamine, Lynda},
	month = dec,
	year = {2021},
	note = {arXiv: 2112.04344},
	keywords = {Computer Science - Computation and Language, Computer Science - Information Retrieval, Computer Science - Machine Learning},
	file = {Djeddal et al. - 2021 - Does Structure Matter Leveraging Data-to-Text Gen.pdf:/Users/marwah/Zotero/storage/YNGTQS59/Djeddal et al. - 2021 - Does Structure Matter Leveraging Data-to-Text Gen.pdf:application/pdf},
}

@article{nogueira_multi-stage_2019,
	title = {Multi-{Stage} {Document} {Ranking} with {BERT}},
	url = {http://arxiv.org/abs/1910.14424},
	abstract = {The advent of deep neural networks pretrained via language modeling tasks has spurred a number of successful applications in natural language processing. This work explores one such popular model, BERT, in the context of document ranking. We propose two variants, called monoBERT and duoBERT, that formulate the ranking problem as pointwise and pairwise classiﬁcation, respectively. These two models are arranged in a multistage ranking architecture to form an end-toend search system. One major advantage of this design is the ability to trade off quality against latency by controlling the admission of candidates into each pipeline stage, and by doing so, we are able to ﬁnd operating points that offer a good balance between these two competing metrics. On two largescale datasets, MS MARCO and TREC CAR, experiments show that our model produces results that are either at or comparable to the state of the art. Ablation studies show the contributions of each component and characterize the latency/quality tradeoff space.},
	language = {en},
	urldate = {2022-03-04},
	journal = {arXiv:1910.14424 [cs]},
	author = {Nogueira, Rodrigo and Yang, Wei and Cho, Kyunghyun and Lin, Jimmy},
	month = oct,
	year = {2019},
	note = {arXiv: 1910.14424},
	keywords = {Computer Science - Information Retrieval, Computer Science - Machine Learning},
	file = {Nogueira et al. - 2019 - Multi-Stage Document Ranking with BERT.pdf:/Users/marwah/Zotero/storage/SICLIEYT/Nogueira et al. - 2019 - Multi-Stage Document Ranking with BERT.pdf:application/pdf},
}

@inproceedings{bhagat_initial_2020,
	address = {Guayaquil Ecuador},
	title = {Initial {Lessons} from {Building} an {IVR}-based {Automated} {Question}-{Answering} {System}},
	isbn = {978-1-4503-8762-0},
	url = {https://dl.acm.org/doi/10.1145/3392561.3397581},
	doi = {10.1145/3392561.3397581},
	abstract = {With improvements in speech recognition and natural language processing capabilities, voicebot systems show promise to run interactive information services for less-literate populations in developing regions. In this context, we describe our initial experiences towards building an automated question-answering system in the domain of sexual and reproductive health and rights. This system is trained on data acquired from an IVR (Interactive Voice Response) platform on which users could record questions, which were then moderated and sent to an expert to get answers. Our goal is to now use this data to build an automated answer retrieval system so that questions can be answered in real time by retrieving an appropriate answer from the corpus of questions and answers available so far. Our insights are likely to be useful for several initiatives using IVR systems and looking to automate their search and retrieval functionality.},
	language = {en},
	urldate = {2022-03-04},
	booktitle = {Proceedings of the 2020 {International} {Conference} on {Information} and {Communication} {Technologies} and {Development}},
	publisher = {ACM},
	author = {Bhagat, Pranav and Prajapati, Sachin Kumar and Seth, Aaditeshwar},
	month = jun,
	year = {2020},
	pages = {1--5},
	file = {Bhagat et al. - 2020 - Initial Lessons from Building an IVR-based Automat.pdf:/Users/marwah/Zotero/storage/ZZLUZUQH/Bhagat et al. - 2020 - Initial Lessons from Building an IVR-based Automat.pdf:application/pdf},
}

@inproceedings{macavaney_opennir_2020,
	address = {Houston TX USA},
	title = {{OpenNIR}: {A} {Complete} {Neural} {Ad}-{Hoc} {Ranking} {Pipeline}},
	isbn = {978-1-4503-6822-3},
	shorttitle = {{OpenNIR}},
	url = {https://dl.acm.org/doi/10.1145/3336191.3371864},
	doi = {10.1145/3336191.3371864},
	language = {en},
	urldate = {2022-03-04},
	booktitle = {Proceedings of the 13th {International} {Conference} on {Web} {Search} and {Data} {Mining}},
	publisher = {ACM},
	author = {MacAvaney, Sean},
	month = jan,
	year = {2020},
	pages = {845--848},
	file = {MacAvaney - 2020 - OpenNIR A Complete Neural Ad-Hoc Ranking Pipeline.pdf:/Users/marwah/Zotero/storage/48XKB5XM/MacAvaney - 2020 - OpenNIR A Complete Neural Ad-Hoc Ranking Pipeline.pdf:application/pdf},
}

@article{fan_pre-training_2021,
	title = {Pre-training {Methods} in {Information} {Retrieval}},
	url = {http://arxiv.org/abs/2111.13853},
	abstract = {The core of information retrieval (IR) is to identify relevant information from large-scale resources and return it as a ranked list to respond to user's information need. Recently, the resurgence of deep learning has greatly advanced this field and leads to a hot topic named NeuIR (i.e., neural information retrieval), especially the paradigm of pre-training methods (PTMs). Owing to sophisticated pre-training objectives and huge model size, pre-trained models can learn universal language representations from massive textual data, which are beneficial to the ranking task of IR. Since there have been a large number of works dedicating to the application of PTMs in IR, we believe it is the right time to summarize the current status, learn from existing methods, and gain some insights for future development. In this survey, we present an overview of PTMs applied in different components of IR system, including the retrieval component, the re-ranking component, and other components. In addition, we also introduce PTMs specifically designed for IR, and summarize available datasets as well as benchmark leaderboards. Moreover, we discuss some open challenges and envision some promising directions, with the hope of inspiring more works on these topics for future research.},
	language = {en},
	urldate = {2022-03-04},
	journal = {arXiv:2111.13853 [cs]},
	author = {Fan, Yixing and Xie, Xiaohui and Cai, Yinqiong and Chen, Jia and Ma, Xinyu and Li, Xiangsheng and Zhang, Ruqing and Guo, Jiafeng and Liu, Yiqun},
	month = nov,
	year = {2021},
	note = {arXiv: 2111.13853},
	keywords = {Computer Science - Information Retrieval},
	file = {Fan et al. - 2021 - Pre-training Methods in Information Retrieval.pdf:/Users/marwah/Zotero/storage/QW4DJ54I/Fan et al. - 2021 - Pre-training Methods in Information Retrieval.pdf:application/pdf},
}

@article{anand_conversational_2020,
	title = {Conversational {Search} -- {A} {Report} from {Dagstuhl} {Seminar} 19461},
	url = {http://arxiv.org/abs/2005.08658},
	abstract = {Dagstuhl Seminar 19461 “Conversational Search” was held on 10-15 November 2019. 44 researchers in Information Retrieval and Web Search, Natural Language Processing, Human Computer Interaction, and Dialogue Systems were invited to share the latest development in the area of Conversational Search and discuss its research agenda and future directions. A 5-day program of the seminar consisted of six introductory and background sessions, three visionary talk sessions, one industry talk session, and seven working groups and reporting sessions. The seminar also had three social events during the program. This report provides the executive summary, overview of invited talks, and ﬁndings from the seven working groups which cover the deﬁnition, evaluation, modelling, explanation, scenarios, applications, and prototype of Conversational Search. The ideas and ﬁndings presented in this report should serve as one of the main sources for diverse research programs on Conversational Search.},
	language = {en},
	urldate = {2022-03-04},
	journal = {arXiv:2005.08658 [cs]},
	author = {Anand, Avishek and Cavedon, Lawrence and Hagen, Matthias and Joho, Hideo and Sanderson, Mark and Stein, Benno},
	month = may,
	year = {2020},
	note = {arXiv: 2005.08658},
	keywords = {Computer Science - Computation and Language, Computer Science - Human-Computer Interaction, Computer Science - Information Retrieval},
	file = {Anand et al. - 2020 - Conversational Search -- A Report from Dagstuhl Se.pdf:/Users/marwah/Zotero/storage/A443BSW6/Anand et al. - 2020 - Conversational Search -- A Report from Dagstuhl Se.pdf:application/pdf},
}

@article{pandya_question_2021,
	title = {Question {Answering} {Survey}: {Directions}, {Challenges}, {Datasets}, {Evaluation} {Matrices}},
	shorttitle = {Question {Answering} {Survey}},
	url = {http://arxiv.org/abs/2112.03572},
	abstract = {The usage and amount of information available on the internet increase over the past decade. This digitization leads to the need for automated answering system to extract fruitful information from redundant and transitional knowledge sources. Such systems are designed to cater the most prominent answer from this giant knowledge source to the user’s query using natural language understanding (NLU) and thus eminently depends on the Question-answering(QA) ﬁeld. Question answering involves but not limited to the steps like mapping of user’s question to pertinent query, retrieval of relevant information, ﬁnding the best suitable answer from the retrieved information etc. The current improvement of deep learning models evince compelling performance improvement in all these tasks.},
	language = {en},
	urldate = {2022-03-04},
	journal = {arXiv:2112.03572 [cs]},
	author = {Pandya, Hariom A. and Bhatt, Brijesh S.},
	month = dec,
	year = {2021},
	note = {arXiv: 2112.03572},
	keywords = {Computer Science - Computation and Language, Computer Science - Human-Computer Interaction, Computer Science - Information Retrieval, Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
	file = {Pandya and Bhatt - 2021 - Question Answering Survey Directions, Challenges,.pdf:/Users/marwah/Zotero/storage/PICC7UTQ/Pandya and Bhatt - 2021 - Question Answering Survey Directions, Challenges,.pdf:application/pdf},
}

@inproceedings{dalton_cast-19_2020,
	address = {Virtual Event China},
	title = {{CAsT}-19: {A} {Dataset} for {Conversational} {Information} {Seeking}},
	isbn = {978-1-4503-8016-4},
	shorttitle = {{CAsT}-19},
	url = {https://dl.acm.org/doi/10.1145/3397271.3401206},
	doi = {10.1145/3397271.3401206},
	abstract = {CAsT-19 is a new dataset that supports research on conversational information seeking. The corpus is 38,426,252 passages from the TREC Complex Answer Retrieval (CAR) and Microsoft MAchine Reading COmprehension (MARCO) datasets. Eighty information seeking dialogues (30 train, 50 test) are an average of 9 to 10 questions long. A dialogue may explore a topic broadly or drill down into subtopics. Questions contain ellipsis, implied context, mild topic shifts, and other characteristics of human conversation that may prevent them from being understood in isolation. Relevance assessments are provided for 30 training topics and 20 test topics. CAsT-19 promotes research on conversational information seeking by defining it as a task in which effective passage selection requires understanding a question’s context (the dialogue history). It focuses attention on user modeling, analysis of prior retrieval results, transformation of questions into effective queries, and other topics that have been difficult to study with existing datasets.},
	language = {en},
	urldate = {2022-03-04},
	booktitle = {Proceedings of the 43rd {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {ACM},
	author = {Dalton, Jeffrey and Xiong, Chenyan and Kumar, Vaibhav and Callan, Jamie},
	month = jul,
	year = {2020},
	pages = {1985--1988},
	file = {Dalton et al. - 2020 - CAsT-19 A Dataset for Conversational Information .pdf:/Users/marwah/Zotero/storage/KMTKZPF9/Dalton et al. - 2020 - CAsT-19 A Dataset for Conversational Information .pdf:application/pdf},
}

@article{ageev_answer_nodate,
	title = {The {Answer} is at your {Fingertips}: {Improving} {Passage} {Retrieval} for {Web} {Question} {Answering} with {Search} {Behavior} {Data}},
	abstract = {Passage retrieval is a crucial ﬁrst step of automatic Question Answering (QA). While existing passage retrieval algorithms are effective at selecting document passages most similar to the question, or those that contain the expected answer types, they do not take into account which parts of the document the searchers actually found useful. We propose, to the best of our knowledge, the ﬁrst successful attempt to incorporate searcher examination data into passage retrieval for question answering. Speciﬁcally, we exploit detailed examination data, such as mouse cursor movements and scrolling, to infer the parts of the document the searcher found interesting, and then incorporate this signal into passage retrieval for QA. Our extensive experiments and analysis demonstrate that our method significantly improves passage retrieval, compared to using textual features alone. As an additional contribution, we make available to the research community the code and the search behavior data used in this study, with the hope of encouraging further research in this area.},
	language = {en},
	author = {Ageev, Mikhail and Lagun, Dmitry and Agichtein, Eugene},
	pages = {11},
	file = {Ageev et al. - The Answer is at your Fingertips Improving Passag.pdf:/Users/marwah/Zotero/storage/D3SEYJTU/Ageev et al. - The Answer is at your Fingertips Improving Passag.pdf:application/pdf},
}

@article{zhao_brain-inspired_2021,
	title = {Brain-{Inspired} {Search} {Engine} {Assistant} {Based} on {Knowledge} {Graph}},
	issn = {2162-237X, 2162-2388},
	url = {https://ieeexplore.ieee.org/document/9559716/},
	doi = {10.1109/TNNLS.2021.3113026},
	abstract = {Search engines can quickly respond to a hyperlink list according to query keywords. However, when a query is complex, developers need to repeatedly reﬁne search keywords and open a large number of web pages to ﬁnd and summarize answers. Many research works of question and answering (Q\&A) system attempt to assist search engines by providing simple, accurate, and understandable answers. However, without original semantic contexts, these answers lack explainability, making them difﬁcult for users to trust and adopt. In this article, a brain-inspired search engine assistant named DeveloperBot based on knowledge graph is proposed, which aligns to the cognitive process of humans and has the capacity to answer complex queries with explainability. Speciﬁcally, DeveloperBot ﬁrst constructs a multilayer query graph by splitting a complex multiconstraint query into several ordered constraints. Then, it models a constraint reasoning process as a subgraph search process inspired by a spreading activation model of cognitive science. In the end, novel features of the subgraph are extracted for decision-making. The corresponding reasoning subgraph and answer conﬁdence are derived as explanations. The results of the decision-making demonstrate that DeveloperBot can estimate answers and answer conﬁdences with high accuracy. We implement a prototype and conduct a user study to evaluate whether and how the direct answers and the explanations provided by DeveloperBot can assist developers’ information needs.},
	language = {en},
	urldate = {2022-03-04},
	journal = {IEEE Transactions on Neural Networks and Learning Systems},
	author = {Zhao, Xuejiao and Chen, Huanhuan and Xing, Zhenchang and Miao, Chunyan},
	year = {2021},
	pages = {1--15},
	file = {Zhao et al. - 2021 - Brain-Inspired Search Engine Assistant Based on Kn.pdf:/Users/marwah/Zotero/storage/HY9A4X6T/Zhao et al. - 2021 - Brain-Inspired Search Engine Assistant Based on Kn.pdf:application/pdf},
}

@inproceedings{diriye_leaving_2012,
	address = {Maui, Hawaii, USA},
	title = {Leaving so soon?: understanding and predicting web search abandonment rationales},
	isbn = {978-1-4503-1156-4},
	shorttitle = {Leaving so soon?},
	url = {http://dl.acm.org/citation.cfm?doid=2396761.2398399},
	doi = {10.1145/2396761.2398399},
	abstract = {Users of search engines often abandon their searches. Despite the high frequency of Web search abandonment and its importance to Web search engines, little is known about why searchers abandon beyond that it can be for good or bad reasons. In this paper, we extend previous work by studying search abandonment using both a retrospective survey and an in-situ method that captures abandonment rationales at abandonment time. We show that although satisfaction is a common motivator for abandonment, one-in-five abandonment instances does not relate to satisfaction. We also studied the automatic prediction of the underlying reason for observed abandonment. We used features of the query and the results, interaction with the result page (e.g., cursor movements, scrolling, clicks), and the full search session. We show that our classifiers can learn to accurately predict the reasons for observed search abandonment. Such accurate predictions help search providers estimate user satisfaction for queries without clicks, affording a more complete understanding of search engine performance. Categories and Subject Descriptors H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval – search process, selection process.},
	language = {en},
	urldate = {2022-03-04},
	booktitle = {Proceedings of the 21st {ACM} international conference on {Information} and knowledge management - {CIKM} '12},
	publisher = {ACM Press},
	author = {Diriye, Abdigani and White, Ryen and Buscher, Georg and Dumais, Susan},
	year = {2012},
	pages = {1025},
	file = {Diriye et al. - 2012 - Leaving so soon understanding and predicting web.pdf:/Users/marwah/Zotero/storage/WXKIF5UX/Diriye et al. - 2012 - Leaving so soon understanding and predicting web.pdf:application/pdf},
}

@inproceedings{bernstein_direct_2012,
	address = {Austin Texas USA},
	title = {Direct answers for search queries in the long tail},
	isbn = {978-1-4503-1015-4},
	url = {https://dl.acm.org/doi/10.1145/2207676.2207710},
	doi = {10.1145/2207676.2207710},
	abstract = {Web search engines now offer more than ranked results. Queries on topics like weather, definitions, and movies may return inline results called answers that can resolve a searcher’s information need without any additional interaction. Despite the usefulness of answers, they are limited to popular needs because each answer type is manually authored. To extend the reach of answers to thousands of new information needs, we introduce Tail Answers: a large collection of direct answers that are unpopular individually, but together address a large proportion of search traffic. These answers cover long-tail needs such as the average body temperature for a dog, substitutes for molasses, and the keyboard shortcut for a right-click. We introduce a combination of search log mining and paid crowdsourcing techniques to create Tail Answers. A user study with 361 participants suggests that Tail Answers significantly improved users’ subjective ratings of search quality and their ability to solve needs without clicking through to a result. Our findings suggest that search engines can be extended to directly respond to a large new class of queries.},
	language = {en},
	urldate = {2022-03-04},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Bernstein, Michael S. and Teevan, Jaime and Dumais, Susan and Liebling, Daniel and Horvitz, Eric},
	month = may,
	year = {2012},
	pages = {237--246},
	file = {Bernstein et al. - 2012 - Direct answers for search queries in the long tail.pdf:/Users/marwah/Zotero/storage/RZ4ZQCQR/Bernstein et al. - 2012 - Direct answers for search queries in the long tail.pdf:application/pdf},
}

@inproceedings{williams_is_2016,
	address = {Pisa Italy},
	title = {Is {This} {Your} {Final} {Answer}?: {Evaluating} the {Effect} of {Answers} on {Good} {Abandonment} in {Mobile} {Search}},
	isbn = {978-1-4503-4069-4},
	shorttitle = {Is {This} {Your} {Final} {Answer}?},
	url = {https://dl.acm.org/doi/10.1145/2911451.2914736},
	doi = {10.1145/2911451.2914736},
	abstract = {Answers on mobile search result pages have become a common way to attempt to satisfy users without them needing to click on search results. Many different types of answers exist, such as weather, ﬂight and currency answers. Understanding the effect that these different answer types have on mobile user behavior and how they contribute to satisfaction is important for search engine evaluation. We study these two aspects by analyzing the logs of a commercial search engine and through a user study. Our results show that user click, abandonment and engagement behavior differs depending on the answer types present on a page. Furthermore, we ﬁnd that satisfaction rates differ in the presence of different answer types with simple answer types, such as time zone answers, leading to more satisfaction than more complex answers, such as news answers. Our ﬁndings have implications for the study and application of user satisfaction for search systems.},
	language = {en},
	urldate = {2022-03-04},
	booktitle = {Proceedings of the 39th {International} {ACM} {SIGIR} conference on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {ACM},
	author = {Williams, Kyle and Kiseleva, Julia and Crook, Aidan C. and Zitouni, Imed and Awadallah, Ahmed Hassan and Khabsa, Madian},
	month = jul,
	year = {2016},
	pages = {889--892},
	file = {Williams et al. - 2016 - Is This Your Final Answer Evaluating the Effect .pdf:/Users/marwah/Zotero/storage/V7PY53BA/Williams et al. - 2016 - Is This Your Final Answer Evaluating the Effect .pdf:application/pdf},
}

@article{zhang_beyond_2018,
	title = {Beyond {Query}-{Oriented} {Highlighting}: {Investigating} the {Effect} of {Snippet} {Text} {Highlighting} in {Search} {User} {Behavior}},
	volume = {2018},
	issn = {1687-5265, 1687-5273},
	shorttitle = {Beyond {Query}-{Oriented} {Highlighting}},
	url = {https://www.hindawi.com/journals/cin/2018/7836969/},
	doi = {10.1155/2018/7836969},
	abstract = {Search users rely on result captions including titles, snippets, and URLs to decide whether they should read and click a particular result or not. Snippet usually serves as a query-dependent summary of its corresponding landing page and is therefore treated as one of the most important factors in search interaction process. Although there exist many efforts in improving snippet generation algorithms and incorporating more powerful interaction functions into snippets, little attention is paid to the effect of text highlighting in user behaviors. The highlighting of query terms in search snippets has been regarded as a matter of course and whether there exists a better way in snippet text highlighting remains uninvestigated. In this paper, we try to find out whether the default strategy of highlighting query terms employed by most commercial search engines is the best for search users. Through carefully designed experiments, we show that the retrieval efficiency can be affected by different term-highlighting strategies without changes in snippet contents. We also propose an automatic method which adopts CRF to learn to highlight terms based on word embedding, Wikipedia, and snippet content information. Experimental results show that the proposed method could predict highlighted terms selected by crowd workers with moderate performance.},
	language = {en},
	urldate = {2022-03-04},
	journal = {Computational Intelligence and Neuroscience},
	author = {Zhang, Hui},
	month = dec,
	year = {2018},
	pages = {1--12},
	file = {Zhang - 2018 - Beyond Query-Oriented Highlighting Investigating .pdf:/Users/marwah/Zotero/storage/CKXE87D8/Zhang - 2018 - Beyond Query-Oriented Highlighting Investigating .pdf:application/pdf},
}

@article{zhou_direct_nodate,
	title = {{DIRECT} {ANSWERS} {OR} {BRIEF} {INFORMATIVE} {SUGGESTIONS}? {PERFORMANCE} {OF} {DIFFERENT} {TYPES} {OF} {SEARCH} {ASSISTANCE} {TOOLS} {ON} {DIFFERENT} {TYPES} {OF} {SEARCH} {TASKS}},
	language = {en},
	author = {Zhou, Andi},
	pages = {36},
	file = {Zhou - DIRECT ANSWERS OR BRIEF INFORMATIVE SUGGESTIONS P.pdf:/Users/marwah/Zotero/storage/42759Q9C/Zhou - DIRECT ANSWERS OR BRIEF INFORMATIVE SUGGESTIONS P.pdf:application/pdf},
}

@inproceedings{chilton_addressing_2011,
	address = {Hyderabad, India},
	title = {Addressing people's information needs directly in a web search result page},
	isbn = {978-1-4503-0632-4},
	url = {http://portal.acm.org/citation.cfm?doid=1963405.1963413},
	doi = {10.1145/1963405.1963413},
	abstract = {Web search engines have historically focused on connecting people with information resources. For example, if a person wanted to know when their flight to Hyderabad was leaving, a search engine might connect them with the airline where they could find flight status information. However, search engines have recently begun to try to meet people’s search needs directly, providing, for example, flight status information in response to queries that include an airline and a flight number. In this paper, we use large scale query log analysis to explore the challenges a search engine faces when trying to meet an information need directly in the search result page. We look at how people's interaction behavior changes when inline content is returned, finding that such content can cannibalize clicks from the algorithmic results. We see that in the absence of interaction behavior, an individual's repeat search behavior can be useful in understanding the content's value. We also discuss some of the ways user behavior can be used to provide insight into when inline answers might better trigger and what types of additional information might be included in the results.},
	language = {en},
	urldate = {2022-03-04},
	booktitle = {Proceedings of the 20th international conference on {World} wide web - {WWW} '11},
	publisher = {ACM Press},
	author = {Chilton, Lydia B. and Teevan, Jaime},
	year = {2011},
	pages = {27},
	file = {Chilton and Teevan - 2011 - Addressing people's information needs directly in .pdf:/Users/marwah/Zotero/storage/W98EXV3V/Chilton and Teevan - 2011 - Addressing people's information needs directly in .pdf:application/pdf},
}

@inproceedings{chilton_addressing_2011-1,
	address = {Hyderabad, India},
	title = {Addressing people's information needs directly in a web search result page},
	isbn = {978-1-4503-0632-4},
	url = {http://portal.acm.org/citation.cfm?doid=1963405.1963413},
	doi = {10.1145/1963405.1963413},
	abstract = {Web search engines have historically focused on connecting people with information resources. For example, if a person wanted to know when their flight to Hyderabad was leaving, a search engine might connect them with the airline where they could find flight status information. However, search engines have recently begun to try to meet people’s search needs directly, providing, for example, flight status information in response to queries that include an airline and a flight number. In this paper, we use large scale query log analysis to explore the challenges a search engine faces when trying to meet an information need directly in the search result page. We look at how people's interaction behavior changes when inline content is returned, finding that such content can cannibalize clicks from the algorithmic results. We see that in the absence of interaction behavior, an individual's repeat search behavior can be useful in understanding the content's value. We also discuss some of the ways user behavior can be used to provide insight into when inline answers might better trigger and what types of additional information might be included in the results.},
	language = {en},
	urldate = {2022-03-05},
	booktitle = {Proceedings of the 20th international conference on {World} wide web - {WWW} '11},
	publisher = {ACM Press},
	author = {Chilton, Lydia B. and Teevan, Jaime},
	year = {2011},
	pages = {27},
	file = {Chilton and Teevan - 2011 - Addressing people's information needs directly in .pdf:/Users/marwah/Zotero/storage/CGNFRU9Z/Chilton and Teevan - 2011 - Addressing people's information needs directly in .pdf:application/pdf},
}
